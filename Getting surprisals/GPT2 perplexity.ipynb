{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1zonPQDcZU_xZu6vrh17jWDE-Qci31nwm","timestamp":1684266080815}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d-XPgu8N7wn3","executionInfo":{"status":"ok","timestamp":1684297314672,"user_tz":240,"elapsed":27491,"user":{"displayName":"Kuan-Jung Huang","userId":"16806485055570171866"}},"outputId":"882fbf25-900c-4aca-dfec-58cdf6e4f54b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","source":["from transformers import AutoTokenizer, GPT2LMHeadModel\n","from google.colab import drive, files\n","import torch\n","import os\n","import pandas as pd\n","import numpy as np"],"metadata":{"id":"GaVt5VjR-jaM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7JXi5nyB-jrd","executionInfo":{"status":"ok","timestamp":1684297349490,"user_tz":240,"elapsed":21324,"user":{"displayName":"Kuan-Jung Huang","userId":"16806485055570171866"}},"outputId":"625ce61a-7941-4b6f-c3e3-ccaa2e690d7e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["root_dir = \"drive/My Drive/Colab Notebooks/\"\n","file_name = \"perplexity_corpus.csv\""],"metadata":{"id":"rgkPLUXK-kuM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(root_dir + file_name)"],"metadata":{"id":"Y2AAU8Kf-rHh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tokenize_seq(sent,tokenizer):\n","  return tokenizer('<sos>'+ sent + '<eos>')"],"metadata":{"id":"pE-VwGRpDNKC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WJDfOw0Q87dt","executionInfo":{"status":"ok","timestamp":1684297489403,"user_tz":240,"elapsed":3985,"user":{"displayName":"Kuan-Jung Huang","userId":"16806485055570171866"}},"outputId":"bf68f528-1d20-49e9-c4cc-5f0ac448ac65"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["def getPerplexity(row, model, tokenizer):\n","    para = row.full_paragraph\n","    idx = row.name\n","    n_rows = len(df)\n","\n","    milestone = round(n_rows / 10)\n","\n","    if idx % milestone == 0:\n","        print(f\"\\t{idx/milestone*10}% Complete\")\n","    perps = []\n","    sentences = nltk.tokenize.sent_tokenize(para)\n","    for sent in sentences:\n","      enc_inputs = tokenizer.encode(sent, padding=True)\n","      enc_inputs = torch.tensor(enc_inputs)\n","      # enc_inputs['input_ids'] = torch.tensor(enc_inputs[\"input_ids\"])\n","      # enc_inputs['attention_mask'] = torch.tensor(enc_inputs[\"attention_mask\"])\n","      # enc_inputs['labels'] = enc_inputs['input_ids'].clone()\n","\n","      with torch.no_grad():\n","          outputs = model(enc_inputs)\n","          logits = outputs.logits\n","          loss = outputs.loss\n","\n","      sm = torch.nn.functional.softmax(logits, dim=1)\n","\n","      word_probs = sm[torch.arange(sm.size(0)-1), enc_inputs[1:]]\n","\n","      log_probs = torch.log(word_probs)\n","\n","      perplexity = torch.exp(-torch.sum(log_probs)/len(enc_inputs))\n","\n","      perps.append(perplexity)\n","\n","    \n","\n","    return np.mean(perps)"],"metadata":{"id":"aTBxAL5MCr1m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def getPerplexity(row, model, tokenizer):\n","    para = row.full_paragraph\n","    idx = row.name\n","    n_rows = len(df)\n","\n","    milestone = round(n_rows / 10)\n","\n","    if idx % milestone == 0:\n","        print(f\"\\t{idx/milestone*10}% Complete\")\n","    sentences = nltk.tokenize.sent_tokenize(para)\n","    for sent in sentences:\n","      enc_inputs = tokenizer.encode(sent, padding=True)\n","      enc_inputs = torch.tensor(enc_inputs)\n","      # enc_inputs['input_ids'] = torch.tensor(enc_inputs[\"input_ids\"])\n","      # enc_inputs['attention_mask'] = torch.tensor(enc_inputs[\"attention_mask\"])\n","      # enc_inputs['labels'] = enc_inputs['input_ids'].clone()\n","\n","      with torch.no_grad():\n","          outputs = model(enc_inputs)\n","          logits = outputs.logits\n","          loss = outputs.loss\n","\n","      sm = torch.nn.functional.softmax(logits, dim=1)\n","\n","      word_probs = sm[torch.arange(sm.size(0)-1), enc_inputs[1:]]\n","\n","      log_probs = torch.log(word_probs)\n","\n","      perplexity = -torch.sum(log_probs)/len(enc_inputs)\n","\n","      return torch.exp(perplexity)"],"metadata":{"id":"nKTooKM_9qH8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_paths = []\n","for i,j in zip(['adjunct_island','adjunct_island','complexNP_island','complexNP_island','wh_island','wh_island'],['0','1','0','1','0','1']): \n","  model_paths.append(root_dir+\"GPT2_checkpoints/\"+i+\"/model_\"+j+\"_lr_.00000625_250\")\n","print(model_paths)\n","results_df = df.copy()"],"metadata":{"id":"RGCzp5y6rZtq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684271908393,"user_tz":240,"elapsed":136,"user":{"displayName":"Kuan-Jung Huang","userId":"16806485055570171866"}},"outputId":"f5bd113b-48aa-456a-e776-aee19f437338"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['drive/My Drive/Colab Notebooks/GPT2_checkpoints/adjunct_island/model_0_lr_.00000625_250', 'drive/My Drive/Colab Notebooks/GPT2_checkpoints/adjunct_island/model_1_lr_.00000625_250', 'drive/My Drive/Colab Notebooks/GPT2_checkpoints/complexNP_island/model_0_lr_.00000625_250', 'drive/My Drive/Colab Notebooks/GPT2_checkpoints/complexNP_island/model_1_lr_.00000625_250', 'drive/My Drive/Colab Notebooks/GPT2_checkpoints/wh_island/model_0_lr_.00000625_250', 'drive/My Drive/Colab Notebooks/GPT2_checkpoints/wh_island/model_1_lr_.00000625_250', 'drive/My Drive/Colab Notebooks/GPT2_checkpoints/mix_construction/model_0_lr_.00000625_250', 'drive/My Drive/Colab Notebooks/GPT2_checkpoints/mix_construction/model_1_lr_.00000625_250']\n"]}]},{"cell_type":"code","source":["for mp in model_paths:\n","  print(f\"Evaluating {mp}...\")\n","  tokenizer = AutoTokenizer.from_pretrained('gpt2', bos_token='<sos>', eos_token='<eos>', pad_token='<pad>')\n","  model = GPT2LMHeadModel.from_pretrained(mp)\n","  pps = df.apply(getPerplexity, axis=1, model=model, tokenizer=tokenizer)\n","  results_df.loc[:, \"pps\"] = pps\n","  print(results_df['pps'].mean())\n","  print(results_df['pps'].std()/torch.sqrt(torch.tensor(447)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"wf0sYE0TryOZ","executionInfo":{"status":"error","timestamp":1684273536270,"user_tz":240,"elapsed":1398900,"user":{"displayName":"Kuan-Jung Huang","userId":"16806485055570171866"}},"outputId":"164f7e81-e255-4de9-8e23-9785ab68c960"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Evaluating drive/My Drive/Colab Notebooks/GPT2_checkpoints/adjunct_island/model_0_lr_.00000625_250...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["\t0.0% Complete\n","\t10.0% Complete\n","\t20.0% Complete\n","\t30.0% Complete\n","\t40.0% Complete\n","\t50.0% Complete\n","\t60.0% Complete\n","\t70.0% Complete\n","\t80.0% Complete\n","\t90.0% Complete\n","2.556870163922088e+27\n","tensor(inf)\n","Evaluating drive/My Drive/Colab Notebooks/GPT2_checkpoints/adjunct_island/model_1_lr_.00000625_250...\n"]},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["\t0.0% Complete\n","\t10.0% Complete\n","\t20.0% Complete\n","\t30.0% Complete\n","\t40.0% Complete\n","\t50.0% Complete\n","\t60.0% Complete\n","\t70.0% Complete\n","\t80.0% Complete\n","\t90.0% Complete\n"]},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["9.742170206774324e+22\n","tensor(inf)\n","Evaluating drive/My Drive/Colab Notebooks/GPT2_checkpoints/complexNP_island/model_0_lr_.00000625_250...\n","\t0.0% Complete\n","\t10.0% Complete\n","\t20.0% Complete\n","\t30.0% Complete\n","\t40.0% Complete\n","\t50.0% Complete\n","\t60.0% Complete\n","\t70.0% Complete\n","\t80.0% Complete\n","\t90.0% Complete\n"]},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["115157566332579.8\n","tensor(8.9816e+12)\n","Evaluating drive/My Drive/Colab Notebooks/GPT2_checkpoints/complexNP_island/model_1_lr_.00000625_250...\n","\t0.0% Complete\n","\t10.0% Complete\n","\t20.0% Complete\n","\t30.0% Complete\n","\t40.0% Complete\n","\t50.0% Complete\n","\t60.0% Complete\n","\t70.0% Complete\n","\t80.0% Complete\n","\t90.0% Complete\n","510471.6241610738\n","tensor(58438.4883)\n","Evaluating drive/My Drive/Colab Notebooks/GPT2_checkpoints/wh_island/model_0_lr_.00000625_250...\n"]},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["\t0.0% Complete\n","\t10.0% Complete\n","\t20.0% Complete\n","\t30.0% Complete\n","\t40.0% Complete\n","\t50.0% Complete\n","\t60.0% Complete\n","\t70.0% Complete\n","\t80.0% Complete\n","\t90.0% Complete\n"]},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["9236.550894854587\n","tensor(4030.4827)\n","Evaluating drive/My Drive/Colab Notebooks/GPT2_checkpoints/wh_island/model_1_lr_.00000625_250...\n","\t0.0% Complete\n","\t10.0% Complete\n","\t20.0% Complete\n","\t30.0% Complete\n","\t40.0% Complete\n","\t50.0% Complete\n","\t60.0% Complete\n","\t70.0% Complete\n","\t80.0% Complete\n","\t90.0% Complete\n","6764273.109619686\n","tensor(1131022.3750)\n","Evaluating drive/My Drive/Colab Notebooks/GPT2_checkpoints/mix_construction/model_0_lr_.00000625_250...\n"]},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'drive/My Drive/Colab Notebooks/GPT2_checkpoints/mix_construction/model_0_lr_.00000625_250'. Use `repo_type` argument if needed.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-65-81679bb002f4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Evaluating {mp}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpt2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbos_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'<sos>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'<eos>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'<pad>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2LMHeadModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mpps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetPerplexity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pps\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2250\u001b[0m             \u001b[0mconfig_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2251\u001b[0;31m             config, model_kwargs = cls.config_class.from_pretrained(\n\u001b[0m\u001b[1;32m   2252\u001b[0m                 \u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2253\u001b[0m                 \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"foo\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         ```\"\"\"\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             logger.warning(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             \u001b[0moriginal_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m                 \u001b[0;31m# For any other exception, we throw a generic error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                 raise EnvironmentError(\n\u001b[0m\u001b[1;32m    651\u001b[0m                     \u001b[0;34mf\"Can't load the configuration of '{pretrained_model_name_or_path}'. If you were trying to load it\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                     \u001b[0;34m\" from 'https://huggingface.co/models', make sure you don't have a local directory with the same\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Can't load the configuration of 'drive/My Drive/Colab Notebooks/GPT2_checkpoints/mix_construction/model_0_lr_.00000625_250'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'drive/My Drive/Colab Notebooks/GPT2_checkpoints/mix_construction/model_0_lr_.00000625_250' is the correct path to a directory containing a config.json file"]}]},{"cell_type":"code","source":["model_paths_ = ['gpt2']\n","for i,j in zip(['mix_construction','mix_construction'],['0','1']): \n","  model_paths_.append(root_dir+\"GPT2_checkpoints/\"+i+\"/model_\"+j+\"_lr_.00000625_65\")\n","results_df = df.copy()\n","for mp in model_paths_:\n","  print(f\"Evaluating {mp}...\")\n","  tokenizer = AutoTokenizer.from_pretrained('gpt2', bos_token='<sos>', eos_token='<eos>', pad_token='<pad>')\n","  model = GPT2LMHeadModel.from_pretrained(mp)\n","  pps = df.apply(getPerplexity, axis=1, model=model, tokenizer=tokenizer)\n","  results_df.loc[:, \"pps\"] = pps\n","  print(results_df['pps'].mean())\n","  print(results_df['pps'].std()/torch.sqrt(torch.tensor(447)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g0mgnv3ak2-j","executionInfo":{"status":"ok","timestamp":1684299322160,"user_tz":240,"elapsed":1009048,"user":{"displayName":"Kuan-Jung Huang","userId":"16806485055570171866"}},"outputId":"cc2a39a8-86e6-45eb-cf9e-2a9aaace66ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluating gpt2...\n"]},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["\t0.0% Complete\n","\t10.0% Complete\n","\t20.0% Complete\n","\t30.0% Complete\n","\t40.0% Complete\n","\t50.0% Complete\n","\t60.0% Complete\n","\t70.0% Complete\n","\t80.0% Complete\n","\t90.0% Complete\n","120.081604\n","tensor(3.6052)\n","Evaluating drive/My Drive/Colab Notebooks/GPT2_checkpoints/mix_construction/model_0_lr_.00000625_65...\n"]},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["\t0.0% Complete\n","\t10.0% Complete\n","\t20.0% Complete\n","\t30.0% Complete\n","\t40.0% Complete\n","\t50.0% Complete\n","\t60.0% Complete\n","\t70.0% Complete\n","\t80.0% Complete\n","\t90.0% Complete\n","inf\n","tensor(nan)\n","Evaluating drive/My Drive/Colab Notebooks/GPT2_checkpoints/mix_construction/model_1_lr_.00000625_65...\n"]},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["\t0.0% Complete\n","\t10.0% Complete\n","\t20.0% Complete\n","\t30.0% Complete\n","\t40.0% Complete\n","\t50.0% Complete\n","\t60.0% Complete\n","\t70.0% Complete\n","\t80.0% Complete\n","\t90.0% Complete\n","inf\n","tensor(nan)\n"]}]},{"cell_type":"code","source":["display(results_df)\n","print(type(results_df))\n","print(results_df[' pps'].mean())\n","print(results_df[' pps'].std()/torch.sqrt(torch.tensor(447)))\n","#results_df.to_csv('.csv')\n","#files.download('.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":476},"id":"B8DV1ozksDPY","executionInfo":{"status":"ok","timestamp":1684267466973,"user_tz":240,"elapsed":565,"user":{"displayName":"Kuan-Jung Huang","userId":"16806485055570171866"}},"outputId":"785a553d-f1c4-49a4-9113-296bf0a361f3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["          id                                     full_paragraph  \\\n","0     cj50_0   Unfortunately , however , and for reasons to ...   \n","1    cf08_37   One such wife , Dr. Linden says , became disg...   \n","2    cl06_11   The kick came , sudden and vicious but short ...   \n","3    cl06_28   In the garage he checked the Jeep for signs o...   \n","4     cf30_4   Dartmouth students enjoy other unusual divers...   \n","..       ...                                                ...   \n","442  ch21_11   A substantial increase is estimated in the co...   \n","443  ch21_24   These examples underscore the importance of e...   \n","444  ch19_17   The first year's projects should also be spre...   \n","445  ch19_23   The already appropriated funds within the dis...   \n","446  ch26_11   The new work was a boon to the partnership , ...   \n","\n","                 pps  \n","0    tensor(33.3928)  \n","1    tensor(59.2077)  \n","2    tensor(35.0073)  \n","3    tensor(39.0804)  \n","4    tensor(95.3046)  \n","..               ...  \n","442  tensor(58.1177)  \n","443  tensor(39.7950)  \n","444  tensor(45.3037)  \n","445  tensor(40.3886)  \n","446  tensor(98.2705)  \n","\n","[447 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-f3c5ca06-f699-4766-85a6-f6258af6f3b9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>full_paragraph</th>\n","      <th>pps</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cj50_0</td>\n","      <td>Unfortunately , however , and for reasons to ...</td>\n","      <td>tensor(33.3928)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cf08_37</td>\n","      <td>One such wife , Dr. Linden says , became disg...</td>\n","      <td>tensor(59.2077)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>cl06_11</td>\n","      <td>The kick came , sudden and vicious but short ...</td>\n","      <td>tensor(35.0073)</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cl06_28</td>\n","      <td>In the garage he checked the Jeep for signs o...</td>\n","      <td>tensor(39.0804)</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cf30_4</td>\n","      <td>Dartmouth students enjoy other unusual divers...</td>\n","      <td>tensor(95.3046)</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>442</th>\n","      <td>ch21_11</td>\n","      <td>A substantial increase is estimated in the co...</td>\n","      <td>tensor(58.1177)</td>\n","    </tr>\n","    <tr>\n","      <th>443</th>\n","      <td>ch21_24</td>\n","      <td>These examples underscore the importance of e...</td>\n","      <td>tensor(39.7950)</td>\n","    </tr>\n","    <tr>\n","      <th>444</th>\n","      <td>ch19_17</td>\n","      <td>The first year's projects should also be spre...</td>\n","      <td>tensor(45.3037)</td>\n","    </tr>\n","    <tr>\n","      <th>445</th>\n","      <td>ch19_23</td>\n","      <td>The already appropriated funds within the dis...</td>\n","      <td>tensor(40.3886)</td>\n","    </tr>\n","    <tr>\n","      <th>446</th>\n","      <td>ch26_11</td>\n","      <td>The new work was a boon to the partnership , ...</td>\n","      <td>tensor(98.2705)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>447 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3c5ca06-f699-4766-85a6-f6258af6f3b9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f3c5ca06-f699-4766-85a6-f6258af6f3b9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f3c5ca06-f699-4766-85a6-f6258af6f3b9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","70.87383773769575\n","tensor(2.0163)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_920a249b-cd18-41c0-b63c-06753b956f3a\", \".csv\", 206809)"]},"metadata":{}}]}]}